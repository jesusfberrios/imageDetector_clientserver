{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6jIc0JvPWxvL"
   },
   "source": [
    "# SERVER CODE\n",
    "# Autor: Jesús Berríos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Se importan las bibliotecas a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "import io\n",
    "import uvicorn\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "from enum import Enum\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import StreamingResponse, Response\n",
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folder if not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"images_uploaded\"\n",
    "if not os.path.exists(dir_name):\n",
    "    os.mkdir(dir_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ORNAXD0dWxvV"
   },
   "outputs": [],
   "source": [
    "# Asignamos una instancia de la clase FastAPI a la variable \"app\".\n",
    "# Interacturaremos con la API usando este elemento.\n",
    "app = FastAPI(title='Implementando un modelo de Machine Learning usando FastAPI')\n",
    "\n",
    "# Enlistamos los modelos disponibles usando Enum. Útil cuando tenemos opciones predefinidas.\n",
    "class Model(str, Enum):\n",
    "    yolov3tiny = \"yolov3-tiny\"\n",
    "    yolov3 = \"yolov3\"\n",
    "\n",
    "\n",
    "# Usando @app.get(\"/\") definimos un método GET para el endpoint / (que sería como el \"home\").\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return \"¡Felicitaciones! Tu API está funcionando según lo esperado. Anda ahora a http://localhost:8000/docs.\"\n",
    "\n",
    "\n",
    "# Este endpoint maneja la lógica necesaria para detectar objetos.\n",
    "# Requiere como entrada el modelo deseado y la imagen.\n",
    "# Se añade valor de confidence a la función\n",
    "@app.post(\"/predict\") \n",
    "def prediction(model: Model, file: UploadFile = File(...), conf = 0.5):\n",
    "    \n",
    "    # 0. Se convierte valor de confidence a Float\n",
    "    confidence_value = float(conf)\n",
    "\n",
    "    # 1. Validar el archivo de entrada\n",
    "    filename = file.filename\n",
    "    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
    "    if not fileExtension:\n",
    "        raise HTTPException(status_code=415, detail=\"Tipo de archivo no soportado.\")\n",
    "    \n",
    "    # 2. Transformar la imagen cruda a una imagen CV2\n",
    "    # Leer la imagen como un stream de bytes\n",
    "    image_stream = io.BytesIO(file.file.read())\n",
    "    # Empezar el stream desde el principio (posicion cero)\n",
    "    image_stream.seek(0)\n",
    "    # Escribir el stream en un numpy array\n",
    "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n",
    "    # Decodificar el numpy array como una imagen\n",
    "    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    \n",
    "    # 3. Correr el modelo de detección de objetos\n",
    "    # Correr la detección de objetos\n",
    "    bbox, label, conf = cv.detect_common_objects(image, confidence = confidence_value, model=model)\n",
    "    # Crear una imagen que contenga las cajas delimitadoras y etiquetas\n",
    "    output_image = draw_bbox(image, bbox, label, conf)\n",
    "    # Guardarla en un directorio del server\n",
    "    cv2.imwrite(f'images_uploaded/{filename}', output_image)\n",
    "    \n",
    "    # 4. Transmitir la respuesta de vuelta al cliente\n",
    "    # Abrir la imagen para leerla en formato binario\n",
    "    file_image = open(f'images_uploaded/{filename}', mode=\"rb\")\n",
    "    # Retornar la imagen como un stream usando un formato específico\n",
    "    return StreamingResponse(file_image, media_type=\"image/jpeg\")#,f'Confidence_used={confidence_value}']\n",
    "\n",
    "# Este endpoint maneja la lógica necesaria para contar objetos.\n",
    "# Requiere como entrada el modelo deseado, la imagen, nivel de confidence y objeto a detectar\n",
    "@app.post(\"/countObjects\") \n",
    "def prediction(model: Model, file: UploadFile = File(...), conf = 0.5, object =''):\n",
    "    \n",
    "    # 0. Se transforma el valor de confidence a float\n",
    "    confidence_value = float(conf)\n",
    "\n",
    "    # 1. Validar el archivo de entrada\n",
    "    filename = file.filename\n",
    "    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
    "    if not fileExtension:\n",
    "        raise HTTPException(status_code=415, detail=\"Tipo de archivo no soportado.\")\n",
    "    \n",
    "    # 2. Transformar la imagen cruda a una imagen CV2\n",
    "    # Leer la imagen como un stream de bytes\n",
    "    image_stream = io.BytesIO(file.file.read())\n",
    "    # Empezar el stream desde el principio (posicion cero)\n",
    "    image_stream.seek(0)\n",
    "    # Escribir el stream en un numpy array\n",
    "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n",
    "    # Decodificar el numpy array como una imagen\n",
    "    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # 3. Correr el modelo de detección de objetos\n",
    "    # Correr la detección de objetos\n",
    "    bbox, label, conf = cv.detect_common_objects(image, confidence = confidence_value, model=model)\n",
    "    # Contar la cantidad de objetos requeridas por el cliente\n",
    "    cnt=0\n",
    "    for i in label:\n",
    "        if object in i:\n",
    "            cnt+=1\n",
    "    \n",
    "    # 4. Se valida si el objeto solicitado se puede detectar por el modelo\n",
    "    lista_objetos = ['person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant','bed','dining table','toilet','tv','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book','clock','vase','scissors','teddy bear','hair drier','toothbrush']\n",
    "    if object in lista_objetos:\n",
    "        respuesta = f'Cantidad_{object}={cnt}'\n",
    "    else:\n",
    "        respuesta = 'Favor ingresar un objeto valido para su deteccion'\n",
    "\n",
    "    # Retornar la respuesta como un string con el dato solicitado\n",
    "    return Response(respuesta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_SDCwso8WxvW"
   },
   "source": [
    "### **Start the server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "stbOFHfDWxvW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [2666]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52890 - \"POST /predict?model=yolov3-tiny&conf=0.67 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52901 - \"POST /predict?model=yolov3-tiny&conf=0.67 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52909 - \"POST /predict?model=yolov3-tiny&conf=0.1 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52910 - \"POST /predict?model=yolov3-tiny&conf=0.2 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52911 - \"POST /predict?model=yolov3-tiny&conf=0.3 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52912 - \"POST /predict?model=yolov3-tiny&conf=0.4 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52913 - \"POST /predict?model=yolov3-tiny&conf=0.5 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52914 - \"POST /predict?model=yolov3-tiny&conf=0.6 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52915 - \"POST /predict?model=yolov3-tiny&conf=0.7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52916 - \"POST /predict?model=yolov3-tiny&conf=0.8 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52917 - \"POST /predict?model=yolov3-tiny&conf=0.9 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52919 - \"POST /predict?model=yolov3-tiny&conf=0.1 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52920 - \"POST /predict?model=yolov3-tiny&conf=0.2 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52921 - \"POST /predict?model=yolov3-tiny&conf=0.3 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52922 - \"POST /predict?model=yolov3-tiny&conf=0.4 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52924 - \"POST /predict?model=yolov3-tiny&conf=0.5 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52925 - \"POST /predict?model=yolov3-tiny&conf=0.6 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52926 - \"POST /predict?model=yolov3-tiny&conf=0.7 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52927 - \"POST /predict?model=yolov3-tiny&conf=0.8 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52928 - \"POST /predict?model=yolov3-tiny&conf=0.9 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52931 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52932 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=person HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52933 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52934 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=person HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52935 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52936 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=person HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52937 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52938 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=person HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52939 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52940 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=person HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52941 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52942 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=person HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52943 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52944 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=person HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52948 - \"POST /predict?model=yolov3-tiny&conf=0.001 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52950 - \"POST /countObjects?model=yolov3-tiny&conf=0.001&object=potted%20plant HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [2666]\n"
     ]
    }
   ],
   "source": [
    "# Esto deja correr al servidor en un ambiente interactivo como un Jupyter notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Donde se hospedará el servidor\n",
    "host = \"127.0.0.1\"\n",
    "\n",
    "# ¡Iniciemos el servidor!    \n",
    "uvicorn.run(app, host=host, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "server.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3eb2a422ec359aa519ba3e7ad330f2e24af32748934baa0b36c34c41556d0b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
